Answer **at least one** of the following questions (in 5-7 sentences) and be ready to discuss all of them in class. You will **not** receive extra credit for answering more than one question. 

1. Based on the reading, why do you think it is important for machine learning models to be interpretable? Provide several reasons. Of these reasons, which one do you believe is the most important? Why?

2. Assuming there exists a tradeoff between model performance and model interpretability, how do we determine an appropriate balance? Which of these two qualities do you think it more important? Why?